{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Sentiment Analysis - Multilayer Perceptron\n",
    "\n",
    "The Multilayer Perceptron (**MLP**) is considered one of the most basic building blocks for netural networks. While the simple Perceptron takes data vector as input and computes a single output value, MLP groups many perceptrons, so the output of the single layer is a new vector instead of a single output value.\n",
    "\n",
    "In PyTorch, this is done simply by setting the number of output features in the <code>Linear</code> layer. Additionally, in MLP multiple layers are combined with a nonlinearity between each layer.\n",
    "\n",
    "<img src=\"files/mlp.png\" width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "When it comes to the **Sentiment Analysis task** we are solving, everything except the model itself, stays the same as in previous example: building the dataset, vectorizer, vocabulary, data loader, training loop and the evaluation. We are going to use the one-hot encoding to represent the text of the tweet, as in previous example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Firstly, set up the path to the (preprocessed) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the preprocessed data\n",
    "import os\n",
    "\n",
    "fileDir = os.path.dirname(os.path.realpath('__file__'))\n",
    "absFilePathToPreprocessedDataset = os.path.join(fileDir, '../Data/training.1600000.processed.noemoticon_preprocessed.csv')\n",
    "pathToPreprocessedDataset = os.path.abspath(os.path.realpath(absFilePathToPreprocessedDataset))\n",
    "print (pathToPreprocessedDataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the device to run the training on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the learning rate parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learningRate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the size of the hidden layer for the MLP model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from Common.TwitterDataset import TwitterDataset\n",
    "from Models.ModelMLP import SentimentClassifierMLP\n",
    "\n",
    "# Step #1: Instantiate the dataset\n",
    "# instantiate the dataset\n",
    "dataset = TwitterDataset.load_dataset_and_make_vectorizer(pathToPreprocessedDataset)\n",
    "# get the vectorizer\n",
    "vectorizer = dataset.get_vectorizer()\n",
    "\n",
    "# Step #2: Instantiate the model\n",
    "# instantiate the model\n",
    "model = SentimentClassifierMLP(input_dim=len(vectorizer.text_vocabulary), hidden_dim=hidden_dim, output_dim=len(vectorizer.target_vocabulary))\n",
    "# send model to appropriate device\n",
    "model = model.to(device)\n",
    "\n",
    "# Step #3: Instantiate the loss function\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "# Step #4: Instantiate the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=learningRate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Common.Trainer import Trainer\n",
    "\n",
    "sentiment_analysis_trainer = Trainer(\n",
    "    dataset=dataset,\n",
    "    model=model,\n",
    "    loss_func=loss_func,\n",
    "    optimizer=optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the chosen number of epochs\n",
    "num_epochs = 200\n",
    "# setup the chosen batch size\n",
    "batch_size = 16\n",
    "\n",
    "report = sentiment_analysis_trainer.train(num_epochs=num_epochs, batch_size=batch_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RunHelper import evaluate_model\n",
    "\n",
    "# set the model in eval state\n",
    "model.eval()\n",
    "\n",
    "evaluate_model(sentiment_analysis_trainer, device, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference and classifying new data points\n",
    "\n",
    "Let's do inference on the new data. This is another evaluation method to make qualitative judgement about whether the model is working."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the model on some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RunHelper import run_examples\n",
    "\n",
    "examples = [\n",
    "    \"This is a good day.\",\n",
    "    \"I was very sad yesterday.\",\n",
    "    \"This is a book.\"\n",
    "]\n",
    "\n",
    "run_examples(examples, model, vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More detailed evaluation on the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RunHelper import model_run_and_evaluate\n",
    "\n",
    "model_run_and_evaluate(dataset, vectorizer, model)"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.6.13 ('NLPWorkshop')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "orig_nbformat": 2,
  "pygments_lexer": "ipython3",
  "version": 3,
  "vscode": {
   "interpreter": {
    "hash": "eff8d7d51e26047d069efc853c99b9bd7989bb88649bcc220bbb87d203046f2b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
