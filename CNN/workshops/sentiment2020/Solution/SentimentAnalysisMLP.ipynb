{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis - Multilayer Perceptron\n",
    "\n",
    "The Multilayer Perceptron (**MLP**) is considered one of the most basic building blocks for netural networks. While the simple Perceptron takes data vector as input and computes a single output value, MLP groups many perceptrons, so the output of the single layer is a new vector instead of a single output value.\n",
    "\n",
    "In PyTorch, this is done simply by setting the number of output features in the <code>Linear</code> layer. Additionally, in MLP multiple layers are combined with a nonlinearity between each layer.\n",
    "\n",
    "<img src=\"files/mlp.png\" width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "When it comes to the **Sentiment Analysis task** we are solving, everything except the model itself, stays the same as in previous example: building the dataset, vectorizer, vocabulary, data loader, training loop and the evaluation. We are going to use the one-hot encoding to represent the text of the tweet, as in previous example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Firstly, set up the path to the (preprocessed) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "c:\\Users\\v-tastan\\source\\repos\\PetnicaNLPWorkshop\\Data\\training.1600000.processed.noemoticon_preprocessed.csv\n"
    }
   ],
   "source": [
    "# Path to the preprocessed data\n",
    "import os\n",
    "\n",
    "fileDir = os.path.dirname(os.path.realpath('__file__'))\n",
    "absFilePathToPreprocessedDataset = os.path.join(fileDir, '../Data/training.1600000.processed.noemoticon_preprocessed.csv')\n",
    "pathToPreprocessedDataset = os.path.abspath(os.path.realpath(absFilePathToPreprocessedDataset))\n",
    "print (pathToPreprocessedDataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the device to run the training on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the learning rate parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "learningRate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the size of the hidden layer for the MLP model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from TwitterDataset import TwitterDataset\n",
    "from ModelMLP import SentimentClassifierMLP\n",
    "\n",
    "# Step #1: Instantiate the dataset\n",
    "# instantiate the dataset\n",
    "dataset = TwitterDataset.load_dataset_and_make_vectorizer(pathToPreprocessedDataset)\n",
    "# get the vectorizer\n",
    "vectorizer = dataset.get_vectorizer()\n",
    "\n",
    "# Step #2: Instantiate the model\n",
    "# instantiate the model\n",
    "model = SentimentClassifierMLP(input_dim=len(vectorizer.text_vocabulary), hidden_dim=hidden_dim, output_dim=len(vectorizer.target_vocabulary))\n",
    "# send model to appropriate device\n",
    "model = model.to(device)\n",
    "\n",
    "# Step #3: Instantiate the loss function\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "# Step #4: Instantiate the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=learningRate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Trainer import Trainer\n",
    "\n",
    "sentiment_analysis_trainer = Trainer(\n",
    "    dataset=dataset,\n",
    "    model=model,\n",
    "    loss_func=loss_func,\n",
    "    optimizer=optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the chosen number of epochs\n",
    "num_epochs = 200\n",
    "# setup the chosen batch size\n",
    "batch_size = 16\n",
    "\n",
    "report = sentiment_analysis_trainer.train(num_epochs=num_epochs, batch_size=batch_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(split):\n",
    "    loss, accuracy = sentiment_analysis_trainer.evaluate(split=split, device=device, batch_size=batch_size)\n",
    "\n",
    "    print(\"Loss: {:.3f}\".format(loss))\n",
    "    print(\"Accuracy: {:.3f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Loss: 0.030\nAccuracy: 0.985\n"
    }
   ],
   "source": [
    "evaluate(split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Loss: 3.601\nAccuracy: 0.635\n"
    }
   ],
   "source": [
    "evaluate(split=\"validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Loss: 2.807\nAccuracy: 0.562\n"
    }
   ],
   "source": [
    "evaluate(split=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More detailed evaluation on the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "precision    recall  f1-score   support\n\n         0.0       0.57      0.62      0.59        47\n         1.0       0.63      0.58      0.61        53\n\n    accuracy                           0.60       100\n   macro avg       0.60      0.60      0.60       100\nweighted avg       0.60      0.60      0.60       100\n\nConsfusion matrix:\n[[29 18]\n [22 31]]\n"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# run the model on the tweets from test set \n",
    "y_predicted = dataset.test_df.text.apply(lambda x: predict(text=x, model=model, vectorizer=vectorizer)[0])\n",
    "\n",
    "# compare that with labels\n",
    "print(classification_report(y_true=dataset.test_df.target, y_pred=y_predicted))\n",
    "\n",
    "# plot confusion matrix\n",
    "print(\"Consfusion matrix:\")\n",
    "print(confusion_matrix(y_true=dataset.test_df.target, y_pred=y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference and classifying new data points\n",
    "\n",
    "Let's do inference on the new data. This is another evaluation method to make qualitative judgement about whether the model is working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def predict(text, model, vectorizer):\n",
    "    \"\"\"\n",
    "    Predict the sentiment of the tweet\n",
    "\n",
    "    Args:\n",
    "        text (str): the text of the tweet\n",
    "        model (SentimentClassifierPerceptron): the trained model\n",
    "        vectorizer (TwitterVectorizer): the corresponding vectorizer\n",
    "    Returns:\n",
    "        sentiment of the tweet (int), probability of that prediction (float)\n",
    "    \"\"\"\n",
    "    # vectorize the text of the tweet\n",
    "    vectorized_text = vectorizer.vectorize(text)\n",
    "\n",
    "    # make a tensor with expected size (1, )\n",
    "    vectorized_text = torch.Tensor(vectorized_text).view(1, -1)\n",
    "\n",
    "    # run the model on the vectorized text and apply softmax activation function on the outputs\n",
    "    result = model(vectorized_text, apply_softmax=True)\n",
    "\n",
    "    # find the best class as the one with the highest probability\n",
    "    probability_values, indices = result.max(dim=1)\n",
    "\n",
    "    # take only value of the indices tensor\n",
    "    index = indices.item()\n",
    "\n",
    "    # decode the predicted target index into the sentiment, using target vocabulary\n",
    "    predicted_target = vectorizer.target_vocabulary.find_index(index)\n",
    "\n",
    "    # take only value of the probability_values tensor \n",
    "    probability_value = probability_values.item()\n",
    "\n",
    "    return predicted_target, probability_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the model on some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(1.0, 0.9999960660934448)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"This is a good day.\"\n",
    "\n",
    "predict(text, model, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(0.0, 1.0)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"I was very sad yesterday.\"\n",
    "\n",
    "predict(text, model, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(0.0, 0.9160420894622803)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"This is a book.\"\n",
    "\n",
    "predict(text, model, vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([-0.1231,  0.2401,  0.1812,  0.1450,  0.2999, -0.0496,  0.0606, -0.1524,\n        -0.0403, -0.2370, -0.1232, -0.2028, -0.1009,  0.1240,  0.1100,  0.1449,\n        -0.1224,  0.1463,  0.0079,  0.1855,  0.1215, -0.0800, -0.1753, -0.1551,\n         0.0904, -0.1401, -0.1256,  0.1441, -0.3846,  0.0922, -0.1228,  0.0410,\n        -0.1010,  0.2857,  0.1378, -0.0380,  0.0135,  0.2073,  0.1644,  0.3477,\n         0.0840,  0.3954, -0.0077,  0.1322, -0.0057,  0.0275, -0.2876, -0.0634,\n        -0.1748,  0.1780, -0.0715,  0.1252,  0.0127, -0.1594, -0.0555,  0.1680,\n         0.1182, -0.1301,  0.2109,  0.0600,  0.2014, -0.2095,  0.0212, -0.1024,\n        -0.2291,  0.2514, -0.0104,  0.1280,  0.3569,  0.0088, -0.0157,  0.3473,\n        -0.1694,  0.2535, -0.2317,  0.5992,  0.0851, -0.0855, -0.4178,  0.4111,\n         0.2885,  0.1157,  0.1052,  0.1233,  0.1112, -0.1665, -0.0203, -0.1434,\n         0.0453, -0.2255,  0.0025, -0.0549, -0.1113,  0.1339, -0.0691,  0.0537,\n        -0.2077,  0.1635,  0.2467,  0.4092, -0.4663, -0.2289, -0.2094, -0.1308,\n         0.3934, -0.3075,  0.1839, -0.0467, -0.0354, -0.0443, -0.0692,  0.1840,\n         0.0270,  0.1686,  0.1782, -0.2398, -0.0093,  0.4824,  0.2092, -0.2167,\n         0.2798, -0.1661,  0.1217,  0.2680,  0.2485,  0.2129, -0.2941,  0.0538,\n        -0.0226, -0.1434, -0.1358,  0.0153,  0.3630, -0.1408, -0.1285,  0.1193,\n         0.3600, -0.0282, -0.1008,  0.2265, -0.0211, -0.3095, -0.0527,  0.0970,\n         0.0732, -0.1777, -0.2629,  0.0495, -0.2969,  0.2285, -0.1018,  0.3071,\n         0.0971, -0.2081,  0.3727,  0.0608, -0.0136,  0.2418,  0.2304,  0.4473,\n        -0.1972, -0.1378,  0.1019,  0.1969, -0.3762, -0.1379, -0.2127, -0.0347,\n         0.0359,  0.1952, -0.2933,  0.2399, -0.3611,  0.2292,  0.1740,  0.2469,\n        -0.0161])"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc1_weights = model.fc1.weight.detach()[0]\n",
    "\n",
    "fc1_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "_, indices = torch.sort(fc1_weights, dim=0, descending=True)\n",
    "\n",
    "indices = indices.numpy().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 20 most infuential words in Negative Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "as\nsad\nlittle\nhis\nagain\ncan't\nstill\nplease\ndidn't\nover\nhope\ndo\noff\nsomething\nwith\nam\nnever\nshe\nwhy\nlol\n"
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(vectorizer.text_vocabulary.find_index(indices[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 20 most infuential words in Positive Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "about\nback\nu\ni've\nyou're\nshould\ncan\nmore\nlove\nnight\nsay\nneed\nsure\nwatching\n..\nbut\nbig\nbetter\nfeel\nyeah\n"
    }
   ],
   "source": [
    "indices.reverse()\n",
    "\n",
    "for i in range(20):\n",
    "    print(vectorizer.text_vocabulary.find_index(indices[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}