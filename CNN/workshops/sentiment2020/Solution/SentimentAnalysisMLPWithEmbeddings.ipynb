{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis - Multilayer Perceptron that uses embedding representation of the input sequence\n",
    "\n",
    "Now we are going to introduce the PyTorch module called the <code>Embedding</code> layer, that encapsulates the embedding weight matrix.\n",
    "\n",
    "We are going to build a Multilayer Perceptron model, very similar to the one in previous example, except for the additional <code>Embedding</code> layer that maps the token indices to the embedding vector representation.\n",
    "\n",
    "The vector representation of the entire sequence is calculated as a sum of embedding vectors for all tokens in the sequence. Using some aggregation function like sum, max or average, is a common method to combine embedding vectors of single tokes in such way that it captures the overall context of the entire sequence. \n",
    "\n",
    "<img src=\"files/word2vec.png\" width=\"300\" height=\"500\" align=\"center\"/>\n",
    "\n",
    "\n",
    "Additionally, there will be two options explored: training the weights of the embedding weight matrix from scratch or initializing the weights with some pretrained embedding weights (GloVe) and just fine-tuning it for the specific task of sentiment analysis.\n",
    "\n",
    "\n",
    "Everything except the model itself and the vectorizer, stays very similar as in previous examples: building the dataset, vocabulary, data loader, training loop and the evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Firstly, set up the path to the (preprocessed) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "c:\\Users\\v-tastan\\source\\repos\\PetnicaNLPWorkshop\\Data\\training.1600000.processed.noemoticon_preprocessed.csv\nc:\\Users\\v-tastan\\source\\repos\\PetnicaNLPWorkshop\\Data\\glove.6B.50d.txt\n"
    }
   ],
   "source": [
    "# Path to the preprocessed data\n",
    "import os\n",
    "\n",
    "fileDir = os.path.dirname(os.path.realpath('__file__'))\n",
    "absFilePathToPreprocessedDataset = os.path.join(fileDir, '../Data/training.1600000.processed.noemoticon_preprocessed.csv')\n",
    "absFilePathToGloVe = os.path.join(fileDir, '../Data/glove.6B.50d.txt')\n",
    "pathToPreprocessedDataset = os.path.abspath(os.path.realpath(absFilePathToPreprocessedDataset))\n",
    "pathToGloveEmbeddings = os.path.abspath(os.path.realpath(absFilePathToGloVe))\n",
    "print (pathToPreprocessedDataset)\n",
    "print (pathToGloveEmbeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the device to run the training on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the learning rate parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "learningRate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from TwitterDataset import TwitterDataset\n",
    "from ModelMLPWithEmbeddings import SentimentClassifierMLPWithEmbeddings\n",
    "\n",
    "# Step #1: Instantiate the dataset\n",
    "# instantiate the dataset\n",
    "dataset = TwitterDataset.load_dataset_and_make_vectorizer(pathToPreprocessedDataset, representation=\"indices\")\n",
    "# get the vectorizer\n",
    "vectorizer = dataset.get_vectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option A: Train embeddings from scrach, do not use pre-trained embeddings\n",
    "\n",
    "There are no additional steps requeired, the <code>Embedding</code> Layer's weight matrix should not be set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option B: Use pre-trained embeddings\n",
    "\n",
    "To use pre-trained embeddings, there are three steps:\n",
    "\n",
    "1. Load the pretrained embeddings\n",
    "2. Select only subset of embeddings for the words that are actually present on the data\n",
    "3. Set the <code>Embedding</code> Layer's weight matrix as the loaded subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step #1.B.1: Load the pre-trained embeddings\n",
    "\n",
    "Set the path to GloVe pretrained embeddings file and load these pretrained embeddings into <code>PreTrainedEmbeddings</code> instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PreTrainedEmbeddings import PreTrainedEmbeddings\n",
    "\n",
    "embeddings = PreTrainedEmbeddings.from_embeddings_file(pathToGloveEmbeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step #1.B.2: Initialize the embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of words in the vocabulary\n",
    "word_list = vectorizer.text_vocabulary.to_serializable()[\"token_to_idx\"].keys()\n",
    "\n",
    "# get the pre-trained embedding vectors only for words that appear in the vocabulary\n",
    "embeddings_matrix = embeddings.make_embeddings_matrix(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step #2: Instantiate the model\n",
    "# instantiate the model\n",
    "model = SentimentClassifierMLPWithEmbeddings(\n",
    "    embedding_size=50,\n",
    "    num_embeddings=len(vectorizer.text_vocabulary),\n",
    "    hidden_dim=10,\n",
    "    output_dim=len(vectorizer.target_vocabulary),\n",
    "    padding_idx=vectorizer.text_vocabulary.mask_index,\n",
    "    # Step #1.B.3: set the loaded subset as a weight matrix\n",
    "    pretrained_embedding_matrix=embeddings_matrix,\n",
    ")\n",
    "# send model to appropriate device\n",
    "model = model.to(device)\n",
    "\n",
    "# Step #3: Instantiate the loss function\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "# Step #4: Instantiate the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=learningRate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Trainer import Trainer\n",
    "\n",
    "sentiment_analysis_trainer = Trainer(\n",
    "    dataset=dataset,\n",
    "    model=model,\n",
    "    loss_func=loss_func,\n",
    "    optimizer=optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the chosen number of epochs\n",
    "num_epochs = 50\n",
    "# setup the chosen batch size\n",
    "batch_size = 16\n",
    "\n",
    "report = sentiment_analysis_trainer.train(num_epochs=num_epochs, batch_size=batch_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "SentimentClassifierMLPWithEmbeddings(\n  (embeddings): Embedding(322, 50, padding_idx=0)\n  (fc1): Linear(in_features=50, out_features=10, bias=True)\n  (fc2): Linear(in_features=10, out_features=2, bias=True)\n)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the model in eval state\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(split):\n",
    "    loss, accuracy = sentiment_analysis_trainer.evaluate(split=split, device=device, batch_size=batch_size)\n",
    "\n",
    "    print(\"Loss: {:.3f}\".format(loss))\n",
    "    print(\"Accuracy: {:.3f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Loss: 0.386\nAccuracy: 0.816\n"
    }
   ],
   "source": [
    "evaluate(split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Loss: 0.865\nAccuracy: 0.667\n"
    }
   ],
   "source": [
    "evaluate(split=\"validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Loss: 0.799\nAccuracy: 0.615\n"
    }
   ],
   "source": [
    "evaluate(split=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference and classifying new data points\n",
    "\n",
    "Let's do inference on the new data. This is another evaluation method to make qualitative judgement about whether the model is working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def predict(text, model, vectorizer):\n",
    "    \"\"\"\n",
    "    Predict the sentiment of the tweet\n",
    "\n",
    "    Args:\n",
    "        text (str): the text of the tweet\n",
    "        model (SentimentClassifierPerceptron): the trained model\n",
    "        vectorizer (TwitterVectorizer): the corresponding vectorizer\n",
    "    Returns:\n",
    "        sentiment of the tweet (int), probability of that prediction (float)\n",
    "    \"\"\"\n",
    "    # vectorize the text of the tweet\n",
    "    vectorized_text = vectorizer.vectorize(text)\n",
    "\n",
    "    # make a tensor with expected size (1, )\n",
    "    vectorized_text = torch.Tensor(vectorized_text).view(1, -1)\n",
    "\n",
    "    # set the model in the eval state\n",
    "    model.eval()\n",
    "\n",
    "    # run the model on the vectorized text and apply softmax activation function on the outputs\n",
    "    result = model(vectorized_text, apply_softmax=True)\n",
    "\n",
    "    # find the best class as the one with the highest probability\n",
    "    probability_values, indices = result.max(dim=1)\n",
    "\n",
    "    # take only value of the indices tensor\n",
    "    index = indices.item()\n",
    "\n",
    "    # decode the predicted target index into the sentiment, using target vocabulary\n",
    "    predicted_target = vectorizer.target_vocabulary.find_index(index)\n",
    "\n",
    "    # take only value of the probability_values tensor \n",
    "    probability_value = probability_values.item()\n",
    "\n",
    "    return predicted_target, probability_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the model on some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(1.0, 0.5920077562332153)"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"This is a good day.\"\n",
    "\n",
    "predict(text, model, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(0.0, 0.8469178080558777)"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"I was very sad yesterday.\"\n",
    "\n",
    "predict(text, model, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(0.0, 0.5402117967605591)"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"This is a book.\"\n",
    "\n",
    "predict(text, model, vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More detailed evaluation on the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "precision    recall  f1-score   support\n\n         0.0       0.54      0.96      0.69        47\n         1.0       0.88      0.28      0.43        53\n\n    accuracy                           0.60       100\n   macro avg       0.71      0.62      0.56       100\nweighted avg       0.72      0.60      0.55       100\n\nConsfusion matrix:\n[[45  2]\n [38 15]]\n"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# run the model on the tweets from test set \n",
    "y_predicted = dataset.test_df.text.apply(lambda x: predict(text=x, model=model, vectorizer=vectorizer)[0])\n",
    "\n",
    "# compare that with labels\n",
    "print(classification_report(y_true=dataset.test_df.target, y_pred=y_predicted))\n",
    "\n",
    "# plot confusion matrix\n",
    "print(\"Consfusion matrix:\")\n",
    "print(confusion_matrix(y_true=dataset.test_df.target, y_pred=y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}