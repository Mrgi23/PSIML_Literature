{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis - Elman RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Firstly, set up the path to the (preprocessed) dataset and glove pretrained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "c:\\Users\\v-tastan\\source\\repos\\PetnicaNLPWorkshop\\Data\\training.1600000.processed.noemoticon_preprocessed.csv\nc:\\Users\\v-tastan\\source\\repos\\PetnicaNLPWorkshop\\Data\\glove.6B.50d.txt\n"
    }
   ],
   "source": [
    "# Path to the preprocessed data\n",
    "import os\n",
    "\n",
    "fileDir = os.path.dirname(os.path.realpath('__file__'))\n",
    "absFilePathToPreprocessedDataset = os.path.join(fileDir, '../Data/training.1600000.processed.noemoticon_preprocessed.csv')\n",
    "absFilePathToGloVe = os.path.join(fileDir, '../Data/glove.6B.50d.txt')\n",
    "pathToPreprocessedDataset = os.path.abspath(os.path.realpath(absFilePathToPreprocessedDataset))\n",
    "pathToGloveEmbeddings = os.path.abspath(os.path.realpath(absFilePathToGloVe))\n",
    "print (pathToPreprocessedDataset)\n",
    "print (pathToGloveEmbeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the device to run the training on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the learning rate parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "learningRate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TwitterDataset import TwitterDataset\n",
    "\n",
    "# Step #1: Instantiate the dataset\n",
    "# instantiate the dataset\n",
    "dataset = TwitterDataset.load_dataset_and_make_vectorizer(pathToPreprocessedDataset, representation=\"indices\")\n",
    "# get the vectorizer\n",
    "vectorizer = dataset.get_vectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option B: Use pre-trained embeddings\n",
    "To use pre-trained embeddings, there are three steps:\n",
    "\n",
    "1. Load the pretrained embeddings\n",
    "2. Select only subset of embeddings for the words that are actually present on the data\n",
    "3. Set the Embedding Layer's weight matrix as the loaded subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step #1.B.1: Load the pre-trained embeddings\n",
    "\n",
    "from PreTrainedEmbeddings import PreTrainedEmbeddings\n",
    "\n",
    "embeddings = PreTrainedEmbeddings.from_embeddings_file(pathToGloveEmbeddings)\n",
    "\n",
    "# Step #1.B.2: Initialize the embedding matrix\n",
    "\n",
    "# get list of words in the vocabulary\n",
    "word_list = vectorizer.text_vocabulary.to_serializable()[\"token_to_idx\"].keys()\n",
    "\n",
    "# get the pre-trained embedding vectors only for words that appear in the vocabulary\n",
    "embeddings_matrix = embeddings.make_embeddings_matrix(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from ModelElmanRNN import SentimentClassifierElmanRNN\n",
    "\n",
    "# Step #2: Instantiate the model\n",
    "# instantiate the model\n",
    "model = SentimentClassifierElmanRNN(\n",
    "    embedding_size=50,\n",
    "    num_embeddings=len(vectorizer.text_vocabulary),\n",
    "    rnn_hidden_dim=10,\n",
    "    output_dim=len(vectorizer.target_vocabulary),\n",
    "    padding_idx=vectorizer.text_vocabulary.mask_index,\n",
    "    batch_first=True,\n",
    "    # Step #1.B.3: set the loaded subset as a weight matrix\n",
    "    pretrained_embedding_matrix=embeddings_matrix,\n",
    ")\n",
    "# send model to appropriate device\n",
    "model = model.to(device)\n",
    "\n",
    "# Step #3: Instantiate the loss function\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "# Step #4: Instantiate the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=learningRate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Trainer import Trainer\n",
    "\n",
    "sentiment_analysis_trainer = Trainer(\n",
    "    dataset=dataset,\n",
    "    model=model,\n",
    "    loss_func=loss_func,\n",
    "    optimizer=optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the chosen number of epochs\n",
    "num_epochs = 20\n",
    "# setup the chosen batch size\n",
    "batch_size = 16\n",
    "\n",
    "report = sentiment_analysis_trainer.train(num_epochs=num_epochs, batch_size=batch_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "SentimentClassifierElmanRNN(\n  (embeddings): Embedding(322, 50, padding_idx=0)\n  (rnn): ElmanRNN(\n    (rnn_cell): RNNCell(50, 10)\n  )\n  (fc1): Linear(in_features=10, out_features=10, bias=True)\n  (fc2): Linear(in_features=10, out_features=2, bias=True)\n)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the model in eval state \n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(split):\n",
    "    loss, accuracy = sentiment_analysis_trainer.evaluate(split=split, device=device, batch_size=batch_size)\n",
    "\n",
    "    print(\"Loss: {:.3f}\".format(loss))\n",
    "    print(\"Accuracy: {:.3f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Loss: 0.693\nAccuracy: 0.511\n"
    }
   ],
   "source": [
    "evaluate(split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Loss: 0.692\nAccuracy: 0.542\n"
    }
   ],
   "source": [
    "evaluate(split=\"validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Loss: 0.694\nAccuracy: 0.469\n"
    }
   ],
   "source": [
    "evaluate(split=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference and classifying new data points\n",
    "\n",
    "Let's do inference on the new data. This is another evaluation method to make qualitative judgement about whether the model is working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def predict(text, model, vectorizer):\n",
    "    \"\"\"\n",
    "    Predict the sentiment of the tweet\n",
    "\n",
    "    Args:\n",
    "        text (str): the text of the tweet\n",
    "        model (SentimentClassifierPerceptron): the trained model\n",
    "        vectorizer (TwitterVectorizer): the corresponding vectorizer\n",
    "    Returns:\n",
    "        sentiment of the tweet (int), probability of that prediction (float)\n",
    "    \"\"\"\n",
    "    # vectorize the text of the tweet\n",
    "    vectorized_text = vectorizer.vectorize(text)\n",
    "\n",
    "    # make a tensor with expected size (1, )\n",
    "    vectorized_text = torch.Tensor(vectorized_text).view(1, -1)\n",
    "\n",
    "    # set the model in the eval state\n",
    "    model.eval()\n",
    "\n",
    "    # run the model on the vectorized text and apply softmax activation function on the outputs\n",
    "    result = model(vectorized_text, apply_softmax=True)\n",
    "\n",
    "    # find the best class as the one with the highest probability\n",
    "    probability_values, indices = result.max(dim=1)\n",
    "\n",
    "    # take only value of the indices tensor\n",
    "    index = indices.item()\n",
    "\n",
    "    # decode the predicted target index into the sentiment, using target vocabulary\n",
    "    predicted_target = vectorizer.target_vocabulary.find_index(index)\n",
    "\n",
    "    # take only value of the probability_values tensor \n",
    "    probability_value = probability_values.item()\n",
    "\n",
    "    return predicted_target, probability_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the model on some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(0.0, 0.5463412404060364)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"This is a good day.\"\n",
    "\n",
    "predict(text, model, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(0.0, 0.5632354021072388)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"I was very sad yesterday.\"\n",
    "\n",
    "predict(text, model, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(0.0, 0.5571166276931763)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"This is a book.\"\n",
    "\n",
    "predict(text, model, vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More detailed evaluation on the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "precision    recall  f1-score   support\n\n         0.0       0.48      0.68      0.57        47\n         1.0       0.56      0.36      0.44        53\n\n    accuracy                           0.51       100\n   macro avg       0.52      0.52      0.50       100\nweighted avg       0.52      0.51      0.50       100\n\nConsfusion matrix:\n[[32 15]\n [34 19]]\n"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# run the model on the tweets from test set \n",
    "y_predicted = dataset.test_df.text.apply(lambda x: predict(text=x, model=model, vectorizer=vectorizer)[0])\n",
    "\n",
    "# compare that with labels\n",
    "print(classification_report(y_true=dataset.test_df.target, y_pred=y_predicted))\n",
    "\n",
    "# plot confusion matrix\n",
    "print(\"Consfusion matrix:\")\n",
    "print(confusion_matrix(y_true=dataset.test_df.target, y_pred=y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}