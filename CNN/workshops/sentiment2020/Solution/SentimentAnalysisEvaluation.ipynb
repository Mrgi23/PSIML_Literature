{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis - Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Firstly, set up the path to the (preprocessed) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "c:\\Petnica\\PetnicaNLPWorkshop\\Data\\training.1600000.processed.noemoticon_preprocessed.csv\n"
    }
   ],
   "source": [
    "# Path to the preprocessed data\n",
    "import os\n",
    "\n",
    "fileDir = os.path.dirname(os.path.realpath('__file__'))\n",
    "absFilePathToPreprocessedDataset = os.path.join(fileDir, '../Data/training.1600000.processed.noemoticon_preprocessed.csv')\n",
    "pathToPreprocessedDataset = os.path.abspath(os.path.realpath(absFilePathToPreprocessedDataset))\n",
    "print (pathToPreprocessedDataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the device to run the training on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the learning rate parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "learningRate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from TwitterDataset import TwitterDataset\n",
    "from ModelPerceptron import SentimentClassifierPerceptron\n",
    "\n",
    "# Step #1: Instantiate the dataset\n",
    "# instantiate the dataset\n",
    "dataset = TwitterDataset.load_dataset_and_make_vectorizer(pathToPreprocessedDataset)\n",
    "# get the vectorizer\n",
    "vectorizer = dataset.get_vectorizer()\n",
    "\n",
    "# Step #2: Instantiate the model\n",
    "# instantiate the model\n",
    "model = SentimentClassifierPerceptron(num_features=len(vectorizer.text_vocabulary), output_dim=len(vectorizer.target_vocabulary))\n",
    "# send model to appropriate device\n",
    "model = model.to(device)\n",
    "\n",
    "# Step #3: Instantiate the loss function\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "# Step #4: Instantiate the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=learningRate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Trainer import Trainer\n",
    "\n",
    "sentiment_analysis_trainer = Trainer(\n",
    "    dataset=dataset,\n",
    "    model=model,\n",
    "    loss_func=loss_func,\n",
    "    optimizer=optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the chosen number of epochs\n",
    "num_epochs = 200\n",
    "# setup the chosen batch size\n",
    "batch_size = 16\n",
    "\n",
    "report = sentiment_analysis_trainer.train(num_epochs=num_epochs, batch_size=batch_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(split):\n",
    "    loss, accuracy = sentiment_analysis_trainer.evaluate(split=split, device=device, batch_size=batch_size)\n",
    "\n",
    "    print(\"Loss: {:.3f}\".format(loss))\n",
    "    print(\"Accuracy: {:.3f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Loss: 0.583\nAccuracy: 0.683\n"
    }
   ],
   "source": [
    "evaluate(split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Loss: 0.611\nAccuracy: 0.635\n"
    }
   ],
   "source": [
    "evaluate(split=\"validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Loss: 0.586\nAccuracy: 0.667\n"
    }
   ],
   "source": [
    "evaluate(split=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference and classifying new data points\n",
    "\n",
    "Let's do inference on the new data. This is another evaluation method to make qualitative judgement about whether the model is working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def predict(text, model, vectorizer):\n",
    "    \"\"\"\n",
    "    Predict the sentiment of the tweet\n",
    "\n",
    "    Args:\n",
    "        text (str): the text of the tweet\n",
    "        model (SentimentClassifierPerceptron): the trained model\n",
    "        vectorizer (TwitterVectorizer): the corresponding vectorizer\n",
    "    Returns:\n",
    "        sentiment of the tweet (int), probability of that prediction (float)\n",
    "    \"\"\"\n",
    "    # vectorize the text of the tweet\n",
    "    vectorized_text = vectorizer.vectorize(text)\n",
    "\n",
    "    # make a tensor with expected size (1, )\n",
    "    vectorized_text = torch.Tensor(vectorized_text).view(1, -1)\n",
    "\n",
    "    # run the model on the vectorized text and apply softmax activation function on the outputs\n",
    "    result = model(vectorized_text, apply_softmax=True)\n",
    "\n",
    "    # find the best class as the one with the highest probability\n",
    "    probability_values, indices = result.max(dim=1)\n",
    "\n",
    "    # take only value of the indices tensor\n",
    "    index = indices.item()\n",
    "\n",
    "    # decode the predicted target index into the sentiment, using target vocabulary\n",
    "    predicted_target = vectorizer.target_vocabulary.find_index(index)\n",
    "\n",
    "    # take only value of the probability_values tensor \n",
    "    probability_value = probability_values.item()\n",
    "\n",
    "    return predicted_target, probability_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the model on some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(1.0, 0.5481831431388855)"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "text = \"This is a good day.\"\n",
    "\n",
    "predict(text, model, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(0.0, 0.5802960991859436)"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "text = \"I was very sad yesterday.\"\n",
    "\n",
    "predict(text, model, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(0.0, 0.5485750436782837)"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "text = \"This is a book.\"\n",
    "\n",
    "predict(text, model, vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More detailed evaluation on the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "precision    recall  f1-score   support\n\n         0.0       0.63      0.66      0.65        47\n         1.0       0.69      0.66      0.67        53\n\n    accuracy                           0.66       100\n   macro avg       0.66      0.66      0.66       100\nweighted avg       0.66      0.66      0.66       100\n\nConsfusion matrix:\n[[31 16]\n [18 35]]\n"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# run the model on the tweets from test set \n",
    "y_predicted = dataset.test_df.text.apply(lambda x: predict(text=x, model=model, vectorizer=vectorizer)[0])\n",
    "\n",
    "# compare that with labels\n",
    "print(classification_report(y_true=dataset.test_df.target, y_pred=y_predicted))\n",
    "\n",
    "# plot confusion matrix\n",
    "print(\"Consfusion matrix:\")\n",
    "print(confusion_matrix(y_true=dataset.test_df.target, y_pred=y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([ 0.0112,  0.2577, -0.1487,  0.1158, -0.2133,  0.2401,  0.0293, -0.4294,\n        -0.2259,  0.2441,  0.1021, -0.0997, -0.0358,  0.0919,  0.1688,  0.5477,\n        -0.1074,  0.2740, -0.3591,  0.3816,  0.7429,  0.0837, -0.4510, -0.3665,\n        -0.2547,  0.0701,  0.0649,  0.4849, -0.1010,  0.1412, -0.3777,  0.0610,\n         0.6400,  0.1233, -0.1900, -0.2555,  0.1284, -0.3158,  0.1627,  0.6309,\n        -0.1842,  0.4015,  0.7346,  0.0987, -0.0600,  0.1897,  0.0705, -0.0974,\n        -0.1526,  0.0404, -0.1333, -0.2396,  0.1236, -0.3804,  0.2365, -0.0651,\n         0.0427, -0.0227,  0.6912, -0.0187,  0.0571,  0.2057,  0.3370, -0.0661,\n         0.1534,  0.3430, -0.0386,  0.1598, -0.0829, -0.1074, -0.3581,  0.0551,\n        -0.1597, -0.3796,  0.2563, -0.6876, -0.5059,  0.1989,  0.4228, -0.2822,\n         0.0307,  0.0772])"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "fc1_weights = model.fc1.weight.detach()[0]\n",
    "\n",
    "fc1_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "_, indices = torch.sort(fc1_weights, dim=0, descending=True)\n",
    "\n",
    "indices = indices.numpy().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 20 most infuential words in Negative Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "go\nwant\nnot\ncan't\nhad\nreally\nwill\nout\ndon't\ni\nthis\ngot\nwork\nday\nwe\nI\nmy\nno\nabout\n)\n"
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(vectorizer.text_vocabulary.find_index(indices[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 20 most infuential words in Positive Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tomorrow\n(\nyour\none\ngood\nits\nan\nyou\n!\nwith\nway\nlove\nback\ncan\ngoing\n,\nthat\n\"\ntime\nall\n"
    }
   ],
   "source": [
    "indices.reverse()\n",
    "\n",
    "for i in range(20):\n",
    "    print(vectorizer.text_vocabulary.find_index(indices[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}